version: "3.3"

services:

  monitor.test:
    container_name: monitor.test
    hostname: monitor.test
    build:
      context: ./postgresql/
    image: postgresql-citusdata
    command: /boot.sh
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/postgresql/data
      - ACTING_UID=${UID}
      - ACTING_GID=${GID}
      - MONITOR_PASSWORD=${MONITOR_PASSWORD}
      - MONITOR_PORT=${MONITOR_PORT}
    volumes:
      - ./scripts/boot-root.sh:/boot.sh
      - ./scripts/boot-common.sh:/boot-common.sh
      - ./scripts/boot-monitor.sh:/boot-user.sh
      - ./etc/monitor/pre.d:/initdb.pre.d
      - ./etc/monitor/post.d:/initdb.post.d
      - ./var/monitor:/var/postgresql
    healthcheck:
      test: pg_isready -p ${MONITOR_PORT} -d pg_auto_failover
    #restart: unless-stopped
    networks:
      - test_internal

  hadb1.test:
    container_name: hadb1.test
    hostname: hadb1.test
    image: postgresql-citusdata
    command: /boot.sh
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/postgresql/data
      - ACTING_UID=${UID}
      - ACTING_GID=${GID}
      - REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - DATABASE_PORT=${DATABASE_PORT}
      - PG_NAME=hadb1
      - PG_AUTOCTL_MONITOR=postgresql://autoctl_node:${MONITOR_PASSWORD}@monitor.test:${MONITOR_PORT}/pg_auto_failover?sslmode=require
    volumes:
      - ./scripts/boot-root.sh:/boot.sh
      - ./scripts/boot-common.sh:/boot-common.sh
      - ./scripts/boot-database.sh:/boot-user.sh
      - ./etc/hadb1/pre.d:/initdb.pre.d
      - ./etc/hadb1/post.d:/initdb.post.d
      - ./var/hadb1:/var/postgresql
    healthcheck:
      test: pg_isready -p ${DATABASE_PORT}
      timeout: 1m
      retries: 10
    #restart: unless-stopped
    networks:
      - test_internal
    depends_on:
      monitor.test:
        condition: service_healthy

  hadb2.test:
    container_name: hadb2.test
    hostname: hadb2.test
    image: postgresql-citusdata
    command: /boot.sh
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/postgresql/data
      - ACTING_UID=${UID}
      - ACTING_GID=${GID}
      - REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - DATABASE_PORT=${DATABASE_PORT}
      - PG_NAME=hadb2
      - PG_AUTOCTL_MONITOR=postgresql://autoctl_node:${MONITOR_PASSWORD}@monitor.test:${MONITOR_PORT}/pg_auto_failover?sslmode=require
    volumes:
      - ./scripts/boot-root.sh:/boot.sh
      - ./scripts/boot-common.sh:/boot-common.sh
      - ./scripts/boot-database.sh:/boot-user.sh
      - ./etc/hadb2/pre.d:/initdb.pre.d
      - ./etc/hadb2/post.d:/initdb.post.d
      - ./var/hadb2:/var/postgresql
    healthcheck:
      test: pg_isready -p ${DATABASE_PORT}
      timeout: 1m
      retries: 10
    #restart: unless-stopped
    networks:
      - test_internal
    depends_on:
      monitor.test:
        condition: service_healthy
      hadb1.test:
        condition: service_healthy

  cluster1.test:
    container_name: cluster1.test
    hostname: cluster1.test
    image: postgresql-citusdata
    command: /boot.sh
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/postgresql/data
      - ACTING_UID=${UID}
      - ACTING_GID=${GID}
      - REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - CLUSTER_PORT=${CLUSTER_PORT}
      - PG_NAME=clus1
      - PG_GROUP=11
      - PG_AUTOCTL_MONITOR=postgresql://autoctl_node:${MONITOR_PASSWORD}@db_monitor.test:${MONITOR_PORT}/pg_auto_failover?sslmode=require
    volumes:
      - ./scripts/boot-root.sh:/boot.sh
      - ./scripts/boot-common.sh:/boot-common.sh
      - ./scripts/boot-cluster.sh:/boot-user.sh
      - ./etc/cluster1/pre.d:/initdb.pre.d
      - ./etc/cluster1/post.d:/initdb.post.d
      - ./var/cluster1:/var/postgresql
    healthcheck:
      test: pg_isready -p ${CLUSTER_PORT}
    #restart: unless-stopped
    networks:
      - test_internal
    depends_on:
      monitor.test:
        condition: service_healthy
      hadb1.test:
        condition: service_healthy

  cluster2.test:
    container_name: cluster2.test
    hostname: cluster2.test
    image: postgresql-citusdata
    command: /boot.sh
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/postgresql/data
      - ACTING_UID=${UID}
      - ACTING_GID=${GID}
      - REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - CLUSTER_PORT=${CLUSTER_PORT}
      - PG_NAME=clus2
      - PG_GROUP=12
      - PG_AUTOCTL_MONITOR=postgresql://autoctl_node:${MONITOR_PASSWORD}@db_monitor.test:${MONITOR_PORT}/pg_auto_failover?sslmode=require
    volumes:
      - ./scripts/boot-root.sh:/boot.sh
      - ./scripts/boot-common.sh:/boot-common.sh
      - ./scripts/boot-cluster.sh:/boot-user.sh
      - ./etc/cluster2/pre.d:/initdb.pre.d
      - ./etc/cluster2/post.d:/initdb.post.d
      - ./var/cluster2:/var/postgresql
    healthcheck:
      test: pg_isready -p ${CLUSTER_PORT}
    #restart: unless-stopped
    networks:
      - test_internal
    depends_on:
      monitor.test:
        condition: service_healthy
      hadb1.test:
        condition: service_healthy

networks:
  test_internal:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.103.0.0/16
